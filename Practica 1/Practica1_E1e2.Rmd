---
title: 'Práctica 1: Aprendizaje Automático'
author: "Eloy Bedia García"
date: "10 de Marzo de 2018"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
subtitle: 1. Ejercicios sobre la búsqueda iterativa de óptimos
---

**EJERCICIO 1**

1. Implementar el algoritmo de gradiente descendente.

$var \leftarrow Punto_{inicio}$

$f: \Re^n \rightarrow \Re$

$fderivadas \leftarrow (\frac{\partial f}{\partial x_{0}},...,\frac{\partial f}{\partial x_{i}},...,\frac{\partial f}{\partial x_{n}})$

$\eta \leftarrow Tasa_{aprendizaje}$

Sea $a \in \Re^n$ el anterior punto evaluado segun BGD, $\epsilon \in \Re \mid |f(x) - f(a)| \ge \epsilon$

$limit \leftarrow Max_{iteraciones}$

``` {r}
BatchGradientDescent = function(var, f, fderivadas, mu, epsilon = -Inf, limit = Inf) {
  #el vector 'y' sera utilizado para almacenar las nuevas componentes
  #Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
  y <- var
  dim(y) <- dim(var)
  iteraciones <- 0

  eval_anterior <- Inf
  while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon)  {
    
    #Recorremos cada una de las componentes independientes de la funcion
    #Para cada componente de la funcion hay una derivada parcial
    for(i in 1:dim(var)) {
      #Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misma
      #Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
      #Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
      #Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
      y[i] <- var[i] - mu * eval(fderivadas[i])
    }

    eval_anterior <- eval(f)
    #Actualizamos el punto que evaluaremos
    var <- y
    iteraciones <- iteraciones + 1
    
  }
  
  list(y,iteraciones)
}
```

\newpage


**EJERCICIO 2**

2. Considerar la función $f(u,v) = (u^{3}e^{v-2} - 4v^{3}e^{-u})^{2}$. Usar gradiente descendente para encontrar un mínimo de esta función, comenzando desde el punto (u, v) = (1, 1) y usando una tasa de aprendizaje $\eta$ = 0,1.

``` {r echo=FALSE}
var <- c(0,0)
dim(var) <- 2
f <- expression( ( (var[1] ** 3) * (exp(var[2] - 2) )  - 4 * (var[2] ** 3) * exp(-var[1]) ) ** 2 )
fu <- expression(2 *  (var[1] ** 3 * exp(var[2] - 2) - 4*exp(-var[1])*var[2]**3) * (3*var[1]**2 * exp(var[2] - 2) + 4*exp(-var[1])*var[2]**3))
fv <- expression(2 * (var[1] ** 3 * exp(var[2] - 2) - 4*exp(-var[1])*var[2]**3) * (var[1] ** 3 * exp(var[2] - 2)  - 12*exp(-var[1])*var[2]  ** 2))
fderivadas <- c(fu,fv)
```

``` {r echo = FALSE}
BatchGradientDescentM = function(var, f, fderivadas, mu, epsilon = -Inf, limit = Inf, minimo_alcanzable) {
  #el vector 'y' sera utilizado para almacenar las nuevas componentes
  #Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
  y <- var
  dim(y) <- dim(var)
  iteraciones <- 0

  eval_anterior <- Inf
  while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon && eval(f) > minimo_alcanzable)  {
    
    #Recorremos cada una de las componentes independientes de la funcion
    #Para cada componente de la funcion hay una derivada parcial
    for(i in 1:dim(var)) {
      #Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misma
      #Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
      #Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
      #Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
      y[i] <- var[i] - mu * eval(fderivadas[i])
    }

    eval_anterior <- eval(f)
    #Actualizamos el punto que evaluaremos
    var <- y
    iteraciones <- iteraciones + 1
    
  }
  
  list(y,iteraciones)
}

var <- c(1,1)
dim(var) <- 2
mu <- 0.1
minimo <- 10e-14

res <- BatchGradientDescentM(var, f, fderivadas, mu, minimo_alcanzable = minimo)
punto <- res[[1]]
iteraciones <- res[[2]]
```

\hspace{1cm} a) Calcular analíticamente y mostrar la expresión del gradiente de la función $f(u,v)$

$\nabla f = (\frac{\partial (u^{3}e^{v-2} - 4v^{3}e^{-u})^{2}}{\partial u}, \frac{\partial (u^{3}e^{v-2} - 4v^{3}e^{-u})^{2}}{\partial v})$

$\nabla f = (2 ( u^{3} e^{v - 2}  - 4 v^{3} e^{-u} ) ( 3u^{2} e^{v - 2}  + 4 v^{3} e^{-u} ), 2 ( u^{3} e^{v - 2}  - 4 v^{3} e^{-u} ) (u^{3}e^{v-2} - 12v^{2}e^{-u}))$

\vspace{1.5cm}

\hspace{1cm} b) Cuántas iteraciones tarda el algoritmo en obtener por primera vez un valor de $f(u,v)$ inferior a $10^{-14}$ .
``` {r echo = FALSE}
cat("Para al vanzar el minimo de la función f, el algoritmo utiliado invierte ", iteraciones)
```

\vspace{1.5cm}

\hspace{1cm} c) ¿En qué coordenadas (u, v) se alcanzó por primera vez un valor igual o menor a $10^{-14}$  en el apartado anterior.
``` {r echo = FALSE}
var <- punto
cat("En el punto (",punto[1],",",punto[2],"). El valor f(u,v) en ese punto es ",eval(f))
```

\newpage

**EJERCICIO 3**

3. Considerar ahora la función $f(x,y) = (x-2)^{2} + 2(y+2)^{2} + 2sin(2\pi x)sin(2\pi y)$

```{r echo=FALSE}
var <- c(0,0)
dim(var) <- 2
f <- expression((var[1] - 2) **2 + 2 *(var[2] + 2) ** 2 + 2 * sin(2 *pi * var[1]) * sin(2 * pi * var[2]))
fu <- expression(2 * (var[1] - 2) + 2 * sin(2 * pi * var[2]) * cos(2 * pi * var[1]) * 2 * pi)
fv <- expression(4 * (var[2] + 2) + 2 * sin(2 * pi * var[1]) * cos(2 * pi * var[2]) * 2 * pi)
fderivadas <- c(fu,fv)
```

\hspace{1cm} a) Usar gradiente descendente para minimizar esta función. Usar como punto inicial $(x_{0} = 1, y_{0} = 1)$, tasa de aprendizaje $\eta = 0.01$ y un máximo de 50 iteraciones. Generar un gráfico de cómo desciende el valor de la función con las iteraciones. Repetir el experimento pero usando $\eta = 0,1$, comentar las diferencias y su dependencia de $\eta$.

``` {r include = FALSE}
BatchGradientDescentG = function(var, f, fderivadas, mu, epsilon = -Inf, limit = Inf) {
  y <- var
  dim(y) <- dim(var)

  iteraciones <- 0
  eval_anterior <- Inf
  grafico <- matrix(c(iteraciones,eval(f)), nrow = 1, ncol = 2, byrow = T)
  
  while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon)  {
    for(i in 1:dim(var)) {
      y[i] <- var[i] - mu * eval(fderivadas[i])
    }

    eval_anterior <- eval(f)

    var <- y
    
    grafico <- rbind(grafico, c(iteraciones,eval(f)))
    iteraciones <- iteraciones + 1
  }
  
  list(y,iteraciones,grafico)
}
```

1º Experimento: Aplicamos el gradiente descendente con $\eta = 0.01$

``` {r echo=FALSE}
var <- c(1,1)
dim(var) <- 2
mu <- 0.01
limit <- 50

res <- BatchGradientDescentG(var, f, fderivadas, mu, limit = 50)

graficos <- res[[3]]

plot(graficos, xlab = "Iteraciones", ylab = "Valor")
```

2º Experimento: Aplicamos el gradiente descendente con $\eta = 0.1$

``` {r echo=FALSE}
var <- c(1,1)
dim(var) <- 2
mu <- 0.1
epsilon <- Inf

res <- BatchGradientDescentG(var, f, fderivadas, mu, limit = 50)
punto <- res[[1]]

graficos <- res[[3]]

plot(graficos, xlab = "Iteraciones", ylab = "Valor")
```

La única diferencia entre ambos experimentos ha sido el valor $\eta$, sin embargo, con esta alteración podemos observar que el primero a conseguido alcanzar el valor mínimo posible, por el contrario, el segundo ha estado lejos de conseguirlo.

El valor $f(u,v)$ en el segundo experimento podemos ver que ha estado aproximadamente en el intervalo $(-1,7)$.

Recordemos que $\eta$ es un factor multiplicativo que condiciona el incremento (o decremento) de la variable independiente.

El segundo experimento tenía una tasa de aprendizaje ($\eta$) con valor 0,1. Con lo dicho anteriormente, podemos deducir que el valor $f(u,v)$ ha estado oscilando entorno al mínimo debido a su alta tasa de aprendizaje. Es decir, cuando estaba cerca del mínimo (tanto en sentido positivo como negativo) debido a su tasa de aprendizaje incrementabamos (o decrementabamos) demasiado el valor de la variable independiente, por lo que en vez de llegar al valor del mínimo, pasabamos al otro lado del mismo. Este proceso se ha repetido numerosas veces y por eso su grafica muestra tantos picos.

En el caso del 1º experimento, la tasa de aprendizaje era adecuada y por ello en ningún momento hemos oscilado entorno al mínimo.

\vspace{1.5cm}


\hspace{1cm} b)  Obtener el valor mínimo y los valores de las variables (x, y) en donde se alcanzan cuando el punto de inicio se fija: (2,1, -2,1), (3, -3),(1,5, 1,5),(1, -1). Generar una tabla con los valores obtenidos

```{r echo=FALSE}
mu <- 0.01
epsilon <- 10**-2


var <- c(2.1,-2.1)
dim(var) <- 2

res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)


var <- c(3,-3)
dim(var) <- 2

res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))


var <- c(1.5,1.5)
dim(var) <- 2

res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))


var <- c(1,-1)
dim(var) <- 2

res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))

dimnames(resultados) <- list(c("P(2.1,-2.1)", "P(3,-3)", "P(1.5,1.5)", "P(1,-1)"),c("X","Y","Z"))

print(resultados)
```

\newpage

**EJERCICIO 4**

4. ¿Cuál sería su conclusión sobre la verdadera dificultad de encontrar el mínimo global de una función arbitraria?

a) Encontrar un punto de inicio que te permita llegar al óptimo global sin quedar atascado en óptimos locales.
b) Encontrar una tasa de aprendizaje  que sea lo suficientemente alta como para encontrar el óptimo rapidamente pero sin llegar a oscilar entorno a él.
c) Encontrar un criterio de parada fiable