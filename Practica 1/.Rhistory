#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misa
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
eval_anterior = eval(f)
}
list(y,iteraciones)
}
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- c(0,0)
dim(var) <- 2
f <- expression((var[1] - 2) **2 + 2 *(var[2] + 2) ** 2 + 2 * sin(2 *pi * var[1]) * sin(2 * pi * var[2]))
fu <- expression(2 * (var[1] - 2) + 2 * sin(2 * pi * var[2]) * cos(2 * pi * var[1]) * 2 * pi)
fv <- expression(4 * (var[2] + 2) + 2 * sin(2 * pi * var[1]) * cos(2 * pi * var[2]) * 2 * pi)
fderivadas <- c(fu,fv)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
#var -> Punto de inicio
#f -> funcion a minimizar
#fderivadas -> derivadas parciales
#mu
#epsilon -> minimo alcanzable
#limit -> limite de iteraciones
BatchGradientDescent1 = function(var, f, fderivadas, mu, epsilon,limit = Inf) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
eval_anterior <- 0
iteraciones <- 0
while(eval(f) < epsilon && iteraciones < limit && abs(eval_anterior - eval(f)) >= abs(epsilon))  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misa
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
eval_anterior = eval(f)
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
#var -> Punto de inicio
#f -> funcion a minimizar
#fderivadas -> derivadas parciales
#mu
#epsilon -> minimo alcanzable
#limit -> limite de iteraciones
BatchGradientDescent1 = function(var, f, fderivadas, mu, epsilon,limit = Inf) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
iteraciones <- 0
while(eval(f) > epsilon && iteraciones < limit)  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misa
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
limit <- 1000
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
limit <- 1000
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon,limit)
var <- c(1,1)
dim(var) <- 2
mu <- 0.1
epsilon <- -Inf
limit <- 50
res <- BatchGradientDescentG(var, f, fderivadas, mu, epsilon, limit)
punto <- res[[1]]
graficos <- res[[3]]
plot(graficos, xlab = "Iteraciones", ylab = "Valor")
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
limit <- 50
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon,limit)
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon,limit)
#var -> Punto de inicio
#f -> funcion a minimizar
#fderivadas -> derivadas parciales
#mu
#epsilon -> minimo alcanzable
#limit -> limite de iteraciones
BatchGradientDescent = function(var, f, fderivadas, mu, epsilon,limit = Inf) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
iteraciones <- 0
while(eval(f) > epsilon && iteraciones < limit)  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misa
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)
var <- c(3,-3)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1.5,1.5)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)
var <- c(3,-3)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1.5,-1.5)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1,-1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
dimnames(resultados) <- list(c("P(2.1,-2.1)", "P(3,-3)", "P(1.5,-1.5)", "P(1,-1)"),c("X","Y","Z"))
print(resultados)
#var -> Punto de inicio
#f -> funcion a minimizar
#fderivadas -> derivadas parciales
#mu
#epsilon -> minimo alcanzable
#limit -> limite de iteraciones
BatchGradientDescent = function(var, f, fderivadas, mu, epsilon,limit = Inf) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
iteraciones <- 0
eval_anterior <- Inf
while(eval(f) > epsilon && iteraciones < limit && abs(eval_anterior - eval(f)) >= abs(epsilon))  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misa
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
eval_anterior <- eval(f)
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)
var <- c(3,-3)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1.5,-1.5)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1,-1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
dimnames(resultados) <- list(c("P(2.1,-2.1)", "P(3,-3)", "P(1.5,-1.5)", "P(1,-1)"),c("X","Y","Z"))
print(resultados)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)
var <- c(3,-3)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1.5,1.5)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1,-1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
dimnames(resultados) <- list(c("P(2.1,-2.1)", "P(3,-3)", "P(1.5,-1.5)", "P(1,-1)"),c("X","Y","Z"))
print(resultados)
var <- c(1,1)
dim(var) <- 2
mu <- 0.01
limit <- 50
res <- BatchGradientDescentG(var, f, fderivadas, mu, limit = limit)
#var -> Punto de inicio
#f -> funcion a minimizar
#fderivadas -> derivadas parciales
#mu
#epsilon -> diiferencia minima que se debe dar entre dos evaluaciones consecutiasde la funcion para que el algoritmo siga ejecutando
#limit -> limite de iteraciones
BatchGradientDescent = function(var, f, fderivadas, mu, epsilon = -Inf,limit = Inf) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
iteraciones <- 0
eval_anterior <- Inf
while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon)  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misa
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
eval_anterior <- eval(f)
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(1,1)
dim(var) <- 2
mu <- 0.01
limit <- 50
res <- BatchGradientDescentG(var, f, fderivadas, mu, limit = limit)
BatchGradientDescentG = function(var, f, fderivadas, mu, epsilon = -Inf, limit = Inf) {
y <- var
dim(y) <- dim(var)
iteraciones <- 0
eval_anterior <- Inf
grafico <- matrix(c(iteraciones,eval(f)), nrow = 1, ncol = 2, byrow = T)
while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon)  {
for(i in 1:dim(var)) {
y[i] <- var[i] - mu * eval(fderivadas[i])
}
eval_anterior <- eval(f)
var <- y
grafico <- rbind(grafico, c(iteraciones,eval(f)))
iteraciones <- iteraciones + 1
}
list(y,iteraciones,grafico)
}
var <- c(1,1)
dim(var) <- 2
mu <- 0.01
limit <- 50
res <- BatchGradientDescentG(var, f, fderivadas, mu, limit = limit)
graficos <- res[[3]]
plot(graficos, xlab = "Iteraciones", ylab = "Valor")
var <- c(1,1)
dim(var) <- 2
mu <- 0.01
limit <- 50
res <- BatchGradientDescentG(var, f, fderivadas, limit = 50)
var <- c(1,1)
dim(var) <- 2
mu <- 0.01
limit <- 50
res <- BatchGradientDescentG(var, f, fderivadas, mu, limit = 50)
graficos <- res[[3]]
plot(graficos, xlab = "Iteraciones", ylab = "Valor")
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- -10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- 10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)
var <- c(3,-3)
dim(var) <- 2
mu <- 0.01
epsilon <- 10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1.5,1.5)
dim(var) <- 2
mu <- 0.01
epsilon <- 10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1,-1)
dim(var) <- 2
mu <- 0.01
epsilon <- 10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
dimnames(resultados) <- list(c("P(2.1,-2.1)", "P(3,-3)", "P(1.5,-1.5)", "P(1,-1)"),c("X","Y","Z"))
print(resultados)
var <- c(2.1,-2.1)
dim(var) <- 2
mu <- 0.01
epsilon <- 10**-2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- matrix(c(var[1],var[2],eval(f)), ncol = 3, byrow = T)
var <- c(3,-3)
dim(var) <- 2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1.5,1.5)
dim(var) <- 2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
var <- c(1,-1)
dim(var) <- 2
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
var <- res[[1]]
resultados <- rbind(resultados, c(var[1],var[2],eval(f)))
dimnames(resultados) <- list(c("P(2.1,-2.1)", "P(3,-3)", "P(1.5,-1.5)", "P(1,-1)"),c("X","Y","Z"))
print(resultados)
var <- c(0,0)
dim(var) <- 2
f <- expression( ( (var[1] ** 3) * (exp(var[2] - 2) )  - 4 * (var[2] ** 3) * exp(-var[1]) ) ** 2 )
fu <- expression(2 *  (var[1] ** 3 * exp(var[2] - 2) - 4*exp(-var[1])*var[2]**3) * (3*var[1]**2 * exp(var[2] - 2) + 4*exp(-var[1])*var[2]**3))
fv <- expression(2 * (var[1] ** 3 * exp(var[2] - 2) - 4*exp(-var[1])*var[2]**3) * (var[1] ** 3 * exp(var[2] - 2)  - 12*exp(-var[1])*var[2]  ** 2))
fderivadas <- c(fu,fv)
var <- c(1,1)
dim(var) <- 2
mu <- 0.1
epsilon <- 10**-14
res <- BatchGradientDescent(var, f, fderivadas, mu, epsilon)
punto <- res[[1]]
iteraciones <- res[[2]]
punto
var <- punto
eval(f)
?plot
knit_with_parameters('~/Escritorio/UGR/3º Carrera/2ºCuatrimestre (CSI)/Aprendizaje Automatico/Practicas/Aprendizaje-Automatico/Practica 1/Practica1_E1e2.Rmd')
BatchGradientDescentM = function(var, f, fderivadas, mu, epsilon = -Inf, limit = Inf, minimo_alcanzable) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
iteraciones <- 0
eval_anterior <- Inf
while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon && eval(f) > minimo_alcanzable)  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misma
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
eval_anterior <- eval(f)
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(1,1)
dim(var) <- 2
mu <- 0.1
minimo <- 10**-14
res <- BatchGradientDescentM(var, f, fderivadas, mu, minimo_alcanzable = minimo)
BatchGradientDescentM = function(var, f, fderivadas, mu, epsilon = -Inf, limit = Inf, minimo_alcanzable) {
#el vector 'y' sera utilizado para almacenar las nuevas componentes
#Si las guardaramos directamente en 'var' alterariamos el punto a evaluar en ese momento.
y <- var
dim(y) <- dim(var)
iteraciones <- 0
eval_anterior <- Inf
while(iteraciones < limit && abs(eval_anterior - eval(f)) >= epsilon && eval(f) > minimo_alcanzable)  {
#Recorremos cada una de las componentes independientes de la funcion
#Para cada componente de la funcion hay una derivada parcial
for(i in 1:dim(var)) {
#Evaluamos la derivada en el punto 'var' y seguimos el sentido negativo de la misma
#Si eval(fderivada[i]) < 0 la variable 'var[i]' aumentara siguiendo el sentido negativo
#Si eval(fderivada[i]) > 0 la variable 'var[i]' disminuira siguiendo el sentido negativo
#Si eval(fderivada[i]) = 0 la variable 'var[i]' habra llegado a su valor optimo, por tanto no se alterara
y[i] <- var[i] - mu * eval(fderivadas[i])
}
eval_anterior <- eval(f)
#Actualizamos el punto que evaluaremos
var <- y
iteraciones <- iteraciones + 1
}
list(y,iteraciones)
}
var <- c(1,1)
dim(var) <- 2
mu <- 0.1
minimo <- 4.122791e-09
res <- BatchGradientDescentM(var, f, fderivadas, mu, minimo_alcanzable = minimo)
punto <- res[[1]]
iteraciones <- res[[2]]
punto
m <- matrix(sample(9),ncol = 3, nrow = 3)
m
m[,1]
